{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "489b5dc5",
   "metadata": {},
   "source": [
    "# Comparación de Modelos ResNet18 V2: Con y Sin BatchNorm/Dropout\n",
    "\n",
    "Este notebook implementa y compara dos variantes de ResNet18 con arquitectura tipo embudo según los requisitos de la **Versión 2: Clasificador extendido tipo embudo**:\n",
    "\n",
    "- **V2 SIN BatchNorm y SIN Dropout**: Solo capas Linear + ReLU\n",
    "- **V2 CON BatchNorm y CON Dropout**: Con BatchNorm antes de ReLU y Dropout entre capas\n",
    "\n",
    "**Arquitectura tipo embudo**: 512 → 256 → 128 → num_classes\n",
    "\n",
    "**Objetivos:**\n",
    "- Evaluar el impacto de BatchNorm y Dropout en el rendimiento\n",
    "- Comparar estabilidad de entrenamiento y capacidad de generalización\n",
    "- Analizar curvas de pérdida y métricas de evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f046954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Importar funciones de utilidad\n",
    "from utils.data_proccess import create_dataloaders,create_transforms,load_datasets\n",
    "from utils.train_model import train_model, plot_training_metrics\n",
    "from utils.evaluate_model import evaluate_model\n",
    "from utils.predict_images import predict_single_image\n",
    "\n",
    "print(\"Librerías importadas exitosamente\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05a8a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Prepare Data\n",
    "print(\"Cargando y preparando datos...\")\n",
    "\n",
    "# Configuración de datos\n",
    "data_dir = 'datos'  # Ajustar según tu estructura\n",
    "batch_size = 32\n",
    "image_size = 224\n",
    "\n",
    "# Crear transforms usando la función de utilidad\n",
    "train_transform, val_test_transform = create_transforms(img_size=image_size)\n",
    "\n",
    "# Cargar datasets\n",
    "train_dataset, val_dataset, test_dataset = load_datasets(data_dir, train_transform, val_test_transform)\n",
    "\n",
    "# Crear dataloaders\n",
    "train_loader, val_loader, test_loader = create_dataloaders(\n",
    "    train_dataset, val_dataset, test_dataset,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "# Obtener nombres de clases\n",
    "class_names = train_dataset.classes\n",
    "num_classes = len(class_names)\n",
    "print(f\"Número de clases: {num_classes}\")\n",
    "print(f\"Clases: {class_names}\")\n",
    "print(f\"Tamaño del dataset de entrenamiento: {len(train_dataset)}\")\n",
    "print(f\"Tamaño del dataset de validación: {len(val_dataset)}\")\n",
    "print(f\"Tamaño del dataset de prueba: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f5454e",
   "metadata": {},
   "source": [
    "## Definición de Arquitectura V2 (Sin BatchNorm y Sin Dropout)\n",
    "\n",
    "**Características del modelo:**\n",
    "- Arquitectura tipo embudo con 3 capas ocultas: 512 → 256 → 128 → num_classes\n",
    "- Solo capas Linear con activación ReLU\n",
    "- **Sin BatchNormalization**\n",
    "- **Sin Dropout**\n",
    "- Backbone: ResNet18 preentrenado (features congeladas)\n",
    "- Transfer Learning: Solo entrenar el clasificador personalizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7dee8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet18V2_Sin(nn.Module):\n",
    "    \"\"\"\n",
    "    ResNet18 V2 SIN BatchNorm y SIN Dropout\n",
    "    Arquitectura tipo embudo: 512 → 256 → 128 → num_classes\n",
    "    Solo Linear + ReLU\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes):\n",
    "        super(ResNet18V2_Sin, self).__init__()\n",
    "        \n",
    "        # Cargar ResNet18 preentrenado\n",
    "        self.resnet = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "        \n",
    "        # Congelar las capas del feature extractor\n",
    "        for param in self.resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        # Obtener el número de features del último layer\n",
    "        num_features = self.resnet.fc.in_features\n",
    "        \n",
    "        # Reemplazar el clasificador con arquitectura tipo embudo\n",
    "        self.resnet.fc = nn.Sequential(\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "# Crear el modelo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_v2_sin = ResNet18V2_Sin(num_classes).to(device)\n",
    "\n",
    "print(\"Modelo V2 SIN BatchNorm/Dropout creado:\")\n",
    "print(f\"Dispositivo: {device}\")\n",
    "print(f\"Arquitectura del clasificador:\")\n",
    "print(model_v2_sin.resnet.fc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6f4baf",
   "metadata": {},
   "source": [
    "## Definición de Arquitectura V2 (Con BatchNorm y Con Dropout)\n",
    "\n",
    "**Características del modelo:**\n",
    "- Misma arquitectura tipo embudo: 512 → 256 → 128 → num_classes\n",
    "- **BatchNorm1d antes de cada ReLU** en capas ocultas\n",
    "- **Dropout (rate=0.3)** después de cada ReLU en capas ocultas\n",
    "- Activación ReLU en todas las capas ocultas\n",
    "- Backbone: ResNet18 preentrenado (features congeladas)\n",
    "- **Técnicas de regularización aplicadas** para prevenir overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac94eff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet18V2_Con(nn.Module):\n",
    "    \"\"\"\n",
    "    ResNet18 V2 CON BatchNorm y CON Dropout\n",
    "    Arquitectura tipo embudo: 512 → 256 → 128 → num_classes\n",
    "    BatchNorm antes de ReLU, Dropout entre capas\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes, dropout_rate=0.3):\n",
    "        super(ResNet18V2_Con, self).__init__()\n",
    "        \n",
    "        # Cargar ResNet18 preentrenado\n",
    "        self.resnet = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "        \n",
    "        # Congelar las capas del feature extractor\n",
    "        for param in self.resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        # Obtener el número de features del último layer\n",
    "        num_features = self.resnet.fc.in_features\n",
    "        \n",
    "        # Reemplazar el clasificador con arquitectura tipo embudo + BN + Dropout\n",
    "        self.resnet.fc = nn.Sequential(\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            \n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            \n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            \n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "# Crear el modelo\n",
    "model_v2_con = ResNet18V2_Con(num_classes, dropout_rate=0.3).to(device)\n",
    "\n",
    "print(\"Modelo V2 CON BatchNorm/Dropout creado:\")\n",
    "print(f\"Dispositivo: {device}\")\n",
    "print(f\"Arquitectura del clasificador:\")\n",
    "print(model_v2_con.resnet.fc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30838833",
   "metadata": {},
   "source": [
    "## Configuración de Entrenamiento\n",
    "\n",
    "**Parámetros comunes para ambos modelos:**\n",
    "- **Criterion**: CrossEntropyLoss\n",
    "- **Optimizer**: Adam (lr=0.001)\n",
    "- **Early stopping**: patience=5 épocas\n",
    "- **Épocas máximas**: 50\n",
    "- **Batch size**: 32\n",
    "\n",
    "**Métricas a registrar:**\n",
    "- Pérdidas de entrenamiento y validación\n",
    "- Accuracy de entrenamiento y validación\n",
    "- Época de mejor rendimiento (best_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87849cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Setup and Configuration\n",
    "\n",
    "# Configuración del entrenamiento\n",
    "learning_rate = 0.001\n",
    "num_epochs = 50\n",
    "patience = 5\n",
    "\n",
    "# Criterion (reutilizado para ambos modelos)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizadores para cada modelo\n",
    "optimizer_v2_sin = optim.Adam(model_v2_sin.parameters(), lr=learning_rate)\n",
    "optimizer_v2_con = optim.Adam(model_v2_con.parameters(), lr=learning_rate)\n",
    "\n",
    "# Inicializar listas para tracking de pérdidas\n",
    "train_losses_v2_sin = []\n",
    "val_losses_v2_sin = []\n",
    "train_losses_v2_con = []\n",
    "val_losses_v2_con = []\n",
    "\n",
    "print(\"Configuración de entrenamiento:\")\n",
    "print(f\"Learning rate: {learning_rate}\")\n",
    "print(f\"Número máximo de épocas: {num_epochs}\")\n",
    "print(f\"Early stopping patience: {patience}\")\n",
    "print(f\"Criterion: {criterion}\")\n",
    "print(f\"Optimizadores creados para ambos modelos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e82e36",
   "metadata": {},
   "source": [
    "## Entrenamiento Modelo V2 - Sin Regularización\n",
    "\n",
    "**Modelo a entrenar:** ResNet18V2_Sin\n",
    "- Arquitectura: Solo Linear + ReLU\n",
    "- Sin BatchNorm, Sin Dropout\n",
    "- Objetivo: Establecer baseline de rendimiento sin regularización\n",
    "\n",
    "**Hipótesis:** Este modelo puede ser más propenso al overfitting pero podría converger más rápido inicialmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa49aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"ENTRENANDO MODELO V2 SIN BatchNorm/Dropout\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Entrenar el modelo usando la función de utilidad\n",
    "model_v2_sin, train_losses_v2_sin, val_losses_v2_sin, train_accuracies_v2_sin, val_accuracies_v2_sin, best_epoch_v2_sin = train_model(\n",
    "    model=model_v2_sin,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer_v2_sin,\n",
    "    num_epochs=num_epochs,\n",
    "    device=device,\n",
    "    patience=patience\n",
    ")\n",
    "\n",
    "print(f\"\\nEntrenamiento completado!\")\n",
    "print(f\"Total de épocas: {len(train_losses_v2_sin)}\")\n",
    "print(f\"Mejor época: {best_epoch_v2_sin}\")\n",
    "print(f\"Pérdida de entrenamiento final: {train_losses_v2_sin[-1]:.4f}\")\n",
    "print(f\"Pérdida de validación final: {val_losses_v2_sin[-1]:.4f}\")\n",
    "print(f\"Accuracy de entrenamiento final: {train_accuracies_v2_sin[-1]:.2f}%\")\n",
    "print(f\"Accuracy de validación final: {val_accuracies_v2_sin[-1]:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea955165",
   "metadata": {},
   "source": [
    "## Entrenamiento Modelo V2 - Con Regularización\n",
    "\n",
    "**Modelo a entrenar:** ResNet18V2_Con\n",
    "- Arquitectura: Linear + BatchNorm + ReLU + Dropout\n",
    "- Con BatchNorm y Dropout (rate=0.3)\n",
    "- Objetivo: Evaluar beneficios de las técnicas de regularización\n",
    "\n",
    "**Hipótesis:** Este modelo debería tener mejor generalización y menor overfitting, posiblemente a costa de convergencia más lenta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b705f7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model V2 With BatchNorm/Dropout\n",
    "print(\"=\" * 60)\n",
    "print(\"ENTRENANDO MODELO V2 CON BatchNorm/Dropout\")  # Corregido el título\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Entrenar el modelo usando la función de utilidad\n",
    "model_v2_con, train_losses_v2_con, val_losses_v2_con, train_accuracies_v2_con, val_accuracies_v2_con, best_epoch_v2_con = train_model(\n",
    "    model=model_v2_con,  # Corregido: usar model_v2_con\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer_v2_con,  # Corregido: usar optimizer_v2_con\n",
    "    num_epochs=num_epochs,\n",
    "    device=device,\n",
    "    patience=patience\n",
    ")\n",
    "\n",
    "print(f\"\\nEntrenamiento completado!\")\n",
    "print(f\"Total de épocas: {len(train_losses_v2_con)}\")  # Corregido: usar variables _con\n",
    "print(f\"Mejor época: {best_epoch_v2_con}\")\n",
    "print(f\"Pérdida de entrenamiento final: {train_losses_v2_con[-1]:.4f}\")\n",
    "print(f\"Pérdida de validación final: {val_losses_v2_con[-1]:.4f}\")\n",
    "print(f\"Accuracy de entrenamiento final: {train_accuracies_v2_con[-1]:.2f}%\")\n",
    "print(f\"Accuracy de validación final: {val_accuracies_v2_con[-1]:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5b2aef",
   "metadata": {},
   "source": [
    "## Evaluación Modelo V2 - Sin BatchNorm/Dropout\n",
    "\n",
    "**Evaluación en conjunto de prueba:**\n",
    "- **Dataset**: Test set (datos no vistos durante entrenamiento)\n",
    "- **Métricas**: Accuracy, Precision, Recall por clase\n",
    "- **Visualizaciones**: Matriz de confusión con heatmap\n",
    "- **Análisis**: Classification report detallado\n",
    "\n",
    "**Objetivo:** Medir el rendimiento real del modelo sin regularización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164b5aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model V2 Without BatchNorm/Dropout\n",
    "print(\"=\" * 60)\n",
    "print(\"EVALUACIÓN MODELO V2 SIN BatchNorm/Dropout\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Evaluar el modelo usando las funciones de utilidad (corregido: agregar class_names)\n",
    "accuracy_sin, y_true_sin, y_pred_sin = evaluate_model(\n",
    "    model=model_v2_sin,  \n",
    "    test_loader=test_loader,\n",
    "    class_names=class_names,  # Agregar class_names como parámetro\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(f\"\\nAccuracy V2 Sin BatchNorm/Dropout: {accuracy_sin:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a718c0",
   "metadata": {},
   "source": [
    "## Evaluación Modelo V2 - Con BatchNorm/Dropout\n",
    "\n",
    "**Evaluación en conjunto de prueba:**\n",
    "- **Dataset**: Test set (datos no vistos durante entrenamiento)\n",
    "- **Métricas**: Accuracy, Precision, Recall por clase\n",
    "- **Visualizaciones**: Matriz de confusión con heatmap\n",
    "- **Análisis**: Classification report detallado\n",
    "\n",
    "**Objetivo:** Medir el rendimiento real del modelo con regularización y comparar con el modelo base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eae9adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model V2 With BatchNorm/Dropout\n",
    "print(\"=\" * 60)\n",
    "print(\"EVALUACIÓN MODELO V2 CON BatchNorm/Dropout\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Evaluar el modelo usando las funciones de utilidad (corregido: agregar class_names)\n",
    "accuracy_con, y_true_con, y_pred_con = evaluate_model(\n",
    "    model=model_v2_con,\n",
    "    test_loader=test_loader,\n",
    "    class_names=class_names,  # Agregar class_names como parámetro\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(f\"\\nAccuracy V2 Con BatchNorm/Dropout: {accuracy_con:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191375d8",
   "metadata": {},
   "source": [
    "## Comparación de Curvas de Entrenamiento\n",
    "\n",
    "**Análisis de curvas de pérdida y accuracy:**\n",
    "\n",
    "**Para cada modelo se visualiza:**\n",
    "- Curva de pérdida de entrenamiento vs validación\n",
    "- Curva de accuracy de entrenamiento vs validación\n",
    "- Marcador de la mejor época (best_epoch)\n",
    "- Indicadores de overfitting o underfitting\n",
    "\n",
    "**Métricas clave a comparar:**\n",
    "- Velocidad de convergencia\n",
    "- Estabilidad durante el entrenamiento\n",
    "- Gap entre train/validation (indicador de overfitting)\n",
    "- Valor final de las métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbdf741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar curvas de entrenamiento V2 Sin BatchNorm/Dropout\n",
    "print(\"\\nVisualizando métricas V2 SIN BatchNorm/Dropout:\")\n",
    "plot_training_metrics(\n",
    "    train_losses_v2_sin, \n",
    "    val_losses_v2_sin, \n",
    "    train_accuracies_v2_sin, \n",
    "    val_accuracies_v2_sin, \n",
    "    best_epoch_v2_sin\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7885733d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar curvas de entrenamiento V2 Con BatchNorm/Dropout\n",
    "print(\"\\nVisualizando métricas V2 CON BatchNorm/Dropout:\")\n",
    "plot_training_metrics(\n",
    "    train_losses_v2_con, \n",
    "    val_losses_v2_con, \n",
    "    train_accuracies_v2_con, \n",
    "    val_accuracies_v2_con, \n",
    "    best_epoch_v2_con\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33f8f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumen de Resultados - Versión 2: Clasificador Tipo Embudo\n",
    "print(\"=\" * 70)\n",
    "print(\"RESUMEN DE RESULTADOS - VERSIÓN 2\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nEXPERIMENTO REALIZADO:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"• Arquitectura: ResNet18 + Clasificador tipo embudo\")\n",
    "print(\"• Estructura: 512 → 256 → 128 → num_classes\")\n",
    "print(\"• Transfer Learning: Features congeladas\")\n",
    "print(\"• Dos variantes entrenadas con mismos parámetros\")\n",
    "\n",
    "print(\"\\nCONFIGURACIÓN DE ENTRENAMIENTO:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"• Optimizador: Adam (lr={learning_rate})\")\n",
    "print(f\"• Early stopping: {patience} épocas\")\n",
    "print(f\"• Batch size: {batch_size}\")\n",
    "print(f\"• Dataset: {num_classes} clases, {len(train_dataset)} muestras entrenamiento\")\n",
    "\n",
    "print(\"\\nRESULTADOS OBTENIDOS:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "print(\"MODELO SIN BatchNorm/Dropout:\")\n",
    "print(f\"   • Test Accuracy: {accuracy_sin:.4f} ({accuracy_sin*100:.1f}%)\")\n",
    "print(f\"   • Mejor época: {best_epoch_v2_sin}\")\n",
    "print(f\"   • Total épocas: {len(train_losses_v2_sin)}\")\n",
    "print(f\"   • Loss final train: {train_losses_v2_sin[-1]:.4f}\")\n",
    "print(f\"   • Loss final val: {val_losses_v2_sin[-1]:.4f}\")\n",
    "print(f\"   • Accuracy final train: {train_accuracies_v2_sin[-1]:.1f}%\")\n",
    "print(f\"   • Accuracy final val: {val_accuracies_v2_sin[-1]:.1f}%\")\n",
    "\n",
    "print(\"\\nMODELO CON BatchNorm/Dropout:\")\n",
    "print(f\"   • Test Accuracy: {accuracy_con:.4f} ({accuracy_con*100:.1f}%)\")\n",
    "print(f\"   • Mejor época: {best_epoch_v2_con}\")\n",
    "print(f\"   • Total épocas: {len(train_losses_v2_con)}\")\n",
    "print(f\"   • Loss final train: {train_losses_v2_con[-1]:.4f}\")\n",
    "print(f\"   • Loss final val: {val_losses_v2_con[-1]:.4f}\")\n",
    "print(f\"   • Accuracy final train: {train_accuracies_v2_con[-1]:.1f}%\")\n",
    "print(f\"   • Accuracy final val: {val_accuracies_v2_con[-1]:.1f}%\")\n",
    "\n",
    "print(\"\\nANÁLISIS DE COMPORTAMIENTO:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Gap entre train y validation\n",
    "gap_sin = train_accuracies_v2_sin[-1] - val_accuracies_v2_sin[-1]\n",
    "gap_con = train_accuracies_v2_con[-1] - val_accuracies_v2_con[-1]\n",
    "\n",
    "print(f\"• Gap Train-Validation Sin BN/Dropout: {gap_sin:.1f}%\")\n",
    "print(f\"• Gap Train-Validation Con BN/Dropout: {gap_con:.1f}%\")\n",
    "\n",
    "# Diferencia de accuracy\n",
    "diff_accuracy = accuracy_con - accuracy_sin\n",
    "if diff_accuracy > 0:\n",
    "    print(f\"• Modelo con regularización fue {diff_accuracy:.3f} puntos mejor\")\n",
    "else:\n",
    "    print(f\"• Modelo sin regularización fue {abs(diff_accuracy):.3f} puntos mejor\")\n",
    "\n",
    "# Convergencia\n",
    "diff_epochs = best_epoch_v2_con - best_epoch_v2_sin\n",
    "if diff_epochs < 0:\n",
    "    print(f\"• Modelo con regularización convergió {abs(diff_epochs)} épocas más rápido\")\n",
    "else:\n",
    "    print(f\"• Modelo sin regularización convergió {diff_epochs} épocas más rápido\")\n",
    "\n",
    "print(\"\\nMÉTRICAS GENERADAS:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"• Matrices de confusión para ambos modelos\")\n",
    "print(\"• Classification reports (Precision, Recall, F1)\")\n",
    "print(\"• Curvas de pérdida durante entrenamiento\")\n",
    "print(\"• Curvas de accuracy durante entrenamiento\")\n",
    "print(\"• Evaluación en conjunto de prueba independiente\")\n",
    "\n",
    "print(\"\\nOBSERVACIONES:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Determinar si hubo early stopping\n",
    "if len(train_losses_v2_sin) < num_epochs:\n",
    "    print(f\"• Modelo sin regularización: Early stopping en época {len(train_losses_v2_sin)}\")\n",
    "else:\n",
    "    print(\"• Modelo sin regularización: Entrenó todas las épocas\")\n",
    "\n",
    "if len(train_losses_v2_con) < num_epochs:\n",
    "    print(f\"• Modelo con regularización: Early stopping en época {len(train_losses_v2_con)}\")\n",
    "else:\n",
    "    print(\"• Modelo con regularización: Entrenó todas las épocas\")\n",
    "\n",
    "# Análisis de overfitting\n",
    "if abs(gap_con) < abs(gap_sin):\n",
    "    print(\"• Regularización redujo el overfitting\")\n",
    "else:\n",
    "    print(\"• Regularización no redujo el overfitting significativamente\")\n",
    "\n",
    "print(\"\\nCUMPLIMIENTO DE OBJETIVOS:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"Arquitectura tipo embudo implementada correctamente\")\n",
    "print(\"Dos entrenamientos realizados (con y sin regularización)\")\n",
    "print(\"Early stopping aplicado exitosamente\")\n",
    "print(\"Métricas completas de evaluación obtenidas\")\n",
    "print(\"Comparación de técnicas de regularización completada\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"RESUMEN COMPLETADO\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
