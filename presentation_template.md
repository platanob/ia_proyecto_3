# ğŸ“Š Plantilla de PresentaciÃ³n - Transfer Learning

**Proyecto 3: Transfer Learning para ClasificaciÃ³n de Frutas y Verduras**  
**INFO1185 - Inteligencia Artificial**  
**Prof. Dr. Ricardo Soto CatalÃ¡n**  
**Noviembre 2025**

---

## ğŸ¯ Slide 1: Portada

### Transfer Learning para ClasificaciÃ³n de Frutas y Verduras
**Estudiantes**: [Nombre 1] y [Nombre 2]  
**Curso**: INFO1185 - Inteligencia Artificial  
**Profesor**: Prof. Dr. Ricardo Soto CatalÃ¡n  
**Fecha**: 03 de diciembre de 2025  

**Modelo seleccionado**: [ResNet18 / VGG16 / DenseNet121 / etc.]

---

## ğŸ“‹ Slide 2: DescripciÃ³n del Problema (5 puntos)

### ğŸ¯ Objetivo del Proyecto
- **Problema**: ClasificaciÃ³n automÃ¡tica de frutas y verduras en imÃ¡genes
- **TÃ©cnica**: Transfer Learning con modelos preentrenados
- **DesafÃ­o**: Adaptar modelos de ImageNet a nuestro dominio especÃ­fico

### ğŸ” MotivaciÃ³n
- **Aplicaciones reales**: Sistemas de inventario, clasificaciÃ³n automÃ¡tica, agricultura de precisiÃ³n
- **Beneficios del Transfer Learning**: Menor costo computacional, aprovecha conocimiento previo
- **ComparaciÃ³n**: Evaluar diferentes arquitecturas de clasificador

### ğŸ“Œ Objetivos EspecÃ­ficos
1. Implementar Transfer Learning con [Modelo elegido]
2. Comparar clasificador simple vs. embudo
3. Analizar impacto de tÃ©cnicas de regularizaciÃ³n
4. Evaluar rendimiento con mÃ©tricas estÃ¡ndar

---

## ğŸ“Š Slide 3: DescripciÃ³n del Dataset (5 puntos)

### ğŸ“ Fruits and Vegetables Image Recognition Dataset

#### ğŸ“ˆ EstadÃ­sticas del Dataset
- **Fuente**: Kaggle - Muhammad Ehsan
- **Total de imÃ¡genes**: [X,XXX] imÃ¡genes
- **NÃºmero de clases**: [XX] clases diferentes
- **ResoluciÃ³n**: Variada, redimensionada a 224Ã—224 pÃ­xeles

#### ğŸ—‚ï¸ DivisiÃ³n del Dataset
| Conjunto | Cantidad | Porcentaje |
|----------|----------|------------|
| **Entrenamiento** | [X,XXX] | 70% |
| **ValidaciÃ³n** | [XXX] | 20% |
| **Prueba** | [XXX] | 10% |

#### ğŸ·ï¸ Clases Incluidas
- **Frutas**: [Manzana, Banana, Naranja, ...]
- **Verduras**: [Zanahoria, Tomate, BrÃ³coli, ...]

*[Mostrar grÃ¡fico de distribuciÃ³n de clases y muestras del dataset]*

---

## ğŸ§  Slide 4: Arquitectura del Modelo (10 puntos)

### ğŸ—ï¸ Modelo Base: [Nombre del modelo seleccionado]

#### ğŸ”§ ConfiguraciÃ³n del Backbone
- **Modelo preentrenado**: [ResNet18/VGG16/etc.] entrenado en ImageNet
- **Congelamiento**: Todas las capas del backbone congeladas
- **Extractor de caracterÃ­sticas**: [TamaÃ±o de salida] caracterÃ­sticas

#### ğŸ›ï¸ VersiÃ³n 1: Clasificador Simple
```
Backbone â†’ FC([tamaÃ±o_caracterÃ­sticas] â†’ [num_clases])
```
- âœ… Una Ãºnica capa totalmente conectada
- âŒ Sin Batch Normalization
- âŒ Sin Dropout

#### ğŸ›ï¸ VersiÃ³n 2: Clasificador Embudo
```
Backbone â†’ FC(512) â†’ BN â†’ ReLU â†’ Dropout â†’ 
           FC(256) â†’ BN â†’ ReLU â†’ Dropout â†’ 
           FC([num_clases])
```
- âœ… Arquitectura tipo embudo (512 â†’ 256 â†’ clases)
- âœ… Batch Normalization entre capas
- âœ… Dropout (p=0.3) para regularizaciÃ³n
- âœ… Activaciones ReLU

---

## âš™ï¸ Slide 5: Estrategia de Entrenamiento (10 puntos)

### ğŸ¯ ConfiguraciÃ³n del Entrenamiento

#### ğŸ“Š HiperparÃ¡metros
| ParÃ¡metro | Valor |
|-----------|--------|
| **Learning Rate** | 0.001 |
| **Batch Size** | 32 |
| **Optimizador** | Adam |
| **Weight Decay** | 1e-4 |
| **Ã‰pocas mÃ¡ximas** | 50 |

#### ğŸ›¡ï¸ TÃ©cnicas de RegularizaciÃ³n
- **Early Stopping**: Paciencia de 10 Ã©pocas
- **Data Augmentation** (solo entrenamiento):
  - Flip horizontal aleatorio
  - RotaciÃ³n Â±15Â°
  - ColorJitter (brillo, contraste, saturaciÃ³n)
  - Random Resized Crop

#### ğŸ”„ Experimentos Realizados
1. **V1**: Clasificador simple
2. **V2 sin regularizaciÃ³n**: Embudo sin BN ni Dropout  
3. **V2 con regularizaciÃ³n**: Embudo completo con BN + Dropout

---

## ğŸ“ˆ Slide 6: Resultados Obtenidos (10 puntos)

### ğŸ† ComparaciÃ³n de Rendimiento

| Modelo | PrecisiÃ³n Test | PÃ©rdida Test | ParÃ¡metros Entrenables |
|--------|----------------|--------------|------------------------|
| **V1 Simple** | [XX.X%] | [0.XXX] | [XXX] |
| **V2 Sin Reg** | [XX.X%] | [0.XXX] | [X,XXX] |
| **V2 Con Reg** | [XX.X%] | [0.XXX] | [X,XXX] |

### ğŸ“Š MÃ©tricas Detalladas por Clase
*[Mostrar tabla con Precision, Recall, F1-Score para cada clase]*

### ğŸ¨ Visualizaciones Clave
1. **Curvas de entrenamiento**: PÃ©rdida y precisiÃ³n vs Ã©pocas
2. **Matriz de confusiÃ³n**: Para el mejor modelo
3. **GrÃ¡fico comparativo**: Barras de precisiÃ³n por modelo

*[Insertar grÃ¡ficos reales aquÃ­]*

### ğŸ” Observaciones Principales
- Modelo con mejor rendimiento: **[Nombre]**
- Mejora de V1 a V2: **[+X.X%]**
- Impacto de regularizaciÃ³n: **[+/-X.X%]**

---

## ğŸ”¬ Slide 7: AnÃ¡lisis y DiscusiÃ³n (10 puntos)

### ğŸ“Š Impacto de la Arquitectura
- **V1 vs V2**: El clasificador embudo mostrÃ³ [mejora/similar/peor] rendimiento
- **Capacidad de representaciÃ³n**: Mayor nÃºmero de parÃ¡metros permitiÃ³ [mejor/similar] captura de patrones
- **Complejidad vs Rendimiento**: [AnÃ¡lisis del trade-off]

### ğŸ›¡ï¸ Efecto de las TÃ©cnicas de RegularizaciÃ³n
- **Batch Normalization**: [Impacto observado en estabilidad/convergencia]
- **Dropout**: [Efecto en sobreajuste/generalizaciÃ³n]
- **CombinaciÃ³n BN + Dropout**: [Resultado sinÃ©rgico/individual]

### âš¡ Estabilidad del Entrenamiento
- **Convergencia**: [AnÃ¡lisis de las curvas de pÃ©rdida]
- **Overfitting**: [Observaciones sobre la diferencia train-val]
- **Early Stopping**: Activado en [X] de [Y] experimentos

### ğŸ’» Limitaciones de Google Colab
- **Memoria GPU**: [Limitaciones encontradas]
- **Tiempo de entrenamiento**: [Restricciones temporales]
- **Soluciones aplicadas**: [Batch size reducido, modelos mÃ¡s pequeÃ±os, etc.]

---

## ğŸ Slide 8: Conclusiones (10 puntos)

### âœ… Logros Principales
1. **ImplementaciÃ³n exitosa** de Transfer Learning con [modelo]
2. **ComparaciÃ³n exhaustiva** entre arquitecturas simples y complejas
3. **AnÃ¡lisis detallado** del impacto de tÃ©cnicas de regularizaciÃ³n
4. **EvaluaciÃ³n completa** con mÃ©tricas estÃ¡ndar de clasificaciÃ³n

### ğŸ“Š Hallazgos Clave
- **Mejor modelo**: [Nombre] con [XX.X%] de precisiÃ³n
- **Arquitectura Ã³ptima**: [Simple/Embudo] segÃºn nuestros datos
- **RegularizaciÃ³n**: [Beneficial/No beneficial] en nuestro caso
- **Transfer Learning**: Efectivo para clasificaciÃ³n de frutas/verduras

### ğŸ”® Trabajo Futuro
- **Modelos avanzados**: Probar EfficientNet, Vision Transformers
- **Fine-tuning**: Descongelar capas finales del backbone
- **Data Augmentation**: TÃ©cnicas mÃ¡s sofisticadas (MixUp, CutMix)
- **Ensemble methods**: Combinar mÃºltiples modelos

### ğŸ¯ Lecciones Aprendidas
- Importancia del **balance** entre complejidad y datos disponibles
- **RegularizaciÃ³n** como herramienta clave para generalizaciÃ³n
- **Monitoreo continuo** necesario para evitar overfitting
- **Transfer Learning** como estrategia efectiva para dominios especÃ­ficos

---

## â“ Slide 9: Preguntas Frecuentes y DiscusiÃ³n

### ğŸ¤” Posibles Preguntas del Profesor/Audiencia

**P1: Â¿Por quÃ© eligieron [modelo especÃ­fico]?**
- R: [Razones tÃ©cnicas: tamaÃ±o, rendimiento, recursos disponibles]

**P2: Â¿CÃ³mo manejaron el desbalance de clases?**
- R: [Estrategias aplicadas o por quÃ© no fue necesario]

**P3: Â¿QuÃ© pasarÃ­a si descongelaran capas del backbone?**
- R: [AnÃ¡lisis teÃ³rico basado en literatura y recursos disponibles]

**P4: Â¿CÃ³mo validaron que no hay data leakage?**
- R: [Explicar divisiÃ³n de datasets y validaciÃ³n cruzada]

**P5: Â¿CuÃ¡l serÃ­a el siguiente paso para mejorar resultados?**
- R: [Propuestas concretas y justificadas]

### ğŸ¯ PreparaciÃ³n para Demo
- **CÃ³digo ejecutable** listo para mostrar
- **Modelos entrenados** guardados y disponibles
- **Visualizaciones** preparadas para explicar resultados
- **MÃ©tricas** calculadas y listas para discutir

---

## ğŸ“‹ Checklist de PresentaciÃ³n

### âœ… Antes de Presentar
- [ ] Slides revisados y sin errores
- [ ] Tiempos ensayados (mÃ¡x 8 minutos)
- [ ] CÃ³digo funcionando correctamente
- [ ] Resultados reales incluidos
- [ ] Respuestas a preguntas preparadas
- [ ] ParticipaciÃ³n equilibrada del equipo

### ğŸ“Š Elementos Visuales Requeridos
- [ ] GrÃ¡fico de distribuciÃ³n del dataset
- [ ] Curvas de entrenamiento (pÃ©rdida y precisiÃ³n)
- [ ] Matriz de confusiÃ³n del mejor modelo
- [ ] ComparaciÃ³n entre modelos (grÃ¡fico de barras)
- [ ] Ejemplos de imÃ¡genes clasificadas

### ğŸ¯ Puntos de la RÃºbrica Cubiertos
- [ ] DescripciÃ³n clara del problema (5 pts)
- [ ] Dataset explicado con nÃºmeros (5 pts)
- [ ] Arquitecturas justificadas tÃ©cnicamente (10 pts)
- [ ] Resultados con mÃ©tricas completas (10 pts)
- [ ] Conclusiones sÃ³lidas y conectadas (10 pts)
- [ ] ComunicaciÃ³n fluida y tiempo respetado (10 pts)
- [ ] PreparaciÃ³n para preguntas (10 pts)

---

**ğŸ•’ DuraciÃ³n total**: 8 minutos mÃ¡ximo  
**ğŸ¤ Fecha de presentaciÃ³n**: 03 de diciembre, 13:50 hrs  
**ğŸ“ Entrega del cÃ³digo**: 03 de diciembre, 13:00 hrs

### ğŸ’¡ Consejos Finales
- **Practiquen** la presentaciÃ³n mÃºltiples veces
- **Cronometren** cada secciÃ³n para no exceder 8 minutos  
- **Preparen** respuestas para preguntas tÃ©cnicas comunes
- **Aseguren** participaciÃ³n equilibrada entre integrantes
- **Tengan** backup del cÃ³digo y slides
