{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8a120fe",
   "metadata": {},
   "source": [
    "# Transfer Learning con EfficientNetV2-S - Versión 1 (V1)\n",
    "\n",
    "Este notebook implementa la **Versión 1: Clasificador simple** usando Transfer Learning con EfficientNetV2-S según los requisitos del proyecto.\n",
    "\n",
    "**Características de la Versión 1:**\n",
    "- Modelo base: EfficientNetV2-S preentrenado en ImageNet\n",
    "- **Clasificador simple: una sola capa Fully Connected**\n",
    "- **Sin Batch Normalization adicional**\n",
    "- **Sin Dropout**\n",
    "- **Sin capas ocultas adicionales**\n",
    "- Transfer Learning: Features congeladas, solo clasificador entrenado\n",
    "- Early stopping basado en validation loss\n",
    "\n",
    "**Objetivos:**\n",
    "- Establecer baseline de rendimiento con arquitectura simple\n",
    "- Evaluar efectividad del Transfer Learning\n",
    "- Implementar pipeline completo de entrenamiento y evaluación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0fdc7f",
   "metadata": {},
   "source": [
    "## 1. Configuración Inicial e Imports\n",
    "\n",
    "**Importación de librerías necesarias:**\n",
    "- PyTorch y torchvision para deep learning\n",
    "- Sklearn para métricas de evaluación\n",
    "- Matplotlib/Seaborn para visualización\n",
    "- Funciones de utilidad personalizadas\n",
    "\n",
    "**Configuración del entorno:**\n",
    "- Detección automática de GPU/CPU\n",
    "- Semillas aleatorias para reproducibilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43219c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import time\n",
    "import copy\n",
    "import warnings\n",
    "\n",
    "from utils.predict_images import predict_random_from_test, print_detailed_prediction, predict_single_image, visualize_prediction_result\n",
    "from utils.train_model import train_model, plot_training_metrics\n",
    "from utils.evaluate_model import evaluate_model\n",
    "# Importar funciones de procesamiento de datos\n",
    "from utils.data_proccess import create_transforms, load_datasets, create_dataloaders\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuracion del dispositivo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Dispositivo utilizado: {device}')\n",
    "\n",
    "# Configuracion para reproducibilidad\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14ec3ca",
   "metadata": {},
   "source": [
    "## 2. Carga y Procesamiento de Datos\n",
    "\n",
    "**Implementación de los requisitos de la sección 3.2:**\n",
    "- **Transformaciones apropiadas**: Redimensionado a 224x224, normalización ImageNet\n",
    "- **Data augmentation**: Aplicado en conjunto de entrenamiento\n",
    "- **División de datos**: Train/Validation/Test usando funciones de utilidad\n",
    "\n",
    "**Configuración de datos:**\n",
    "- Batch size: 32\n",
    "- Clases automáticamente detectadas del directorio\n",
    "- DataLoaders optimizados para entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd479bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuracion del proyecto\n",
    "data_dir = \"datos\"\n",
    "img_size = 224\n",
    "batch_size = 32\n",
    "\n",
    "# Crear transformaciones\n",
    "print(\"Creando transformaciones...\")\n",
    "train_transform, val_test_transform = create_transforms(img_size=img_size)\n",
    "\n",
    "# Cargar datasets\n",
    "print(\"Cargando datasets...\")\n",
    "train_dataset, val_dataset, test_dataset = load_datasets(\n",
    "    data_dir, train_transform, val_test_transform\n",
    ")\n",
    "\n",
    "# Mostrar informacion de las clases\n",
    "print(f\"\\nClases detectadas: {train_dataset.classes}\")\n",
    "print(f\"Numero de clases: {len(train_dataset.classes)}\")\n",
    "print(f\"Muestras de entrenamiento: {len(train_dataset)}\")\n",
    "print(f\"Muestras de validacion: {len(val_dataset)}\")\n",
    "print(f\"Muestras de test: {len(test_dataset)}\")\n",
    "\n",
    "# Crear DataLoaders\n",
    "print(\"\\nCreando DataLoaders...\")\n",
    "train_loader, val_loader, test_loader = create_dataloaders(\n",
    "    train_dataset, val_dataset, test_dataset, batch_size=batch_size\n",
    ")\n",
    "\n",
    "print(f\"Batches de entrenamiento: {len(train_loader)}\")\n",
    "print(f\"Batches de validacion: {len(val_loader)}\")\n",
    "print(f\"Batches de test: {len(test_loader)}\")\n",
    "\n",
    "# Guardar variables importantes\n",
    "class_names = train_dataset.classes\n",
    "num_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db557ce3",
   "metadata": {},
   "source": [
    "## 3. Definición del Modelo V1 - Clasificador Simple\n",
    "\n",
    "**Implementación de la Versión 1 según requisitos:**\n",
    "- **Backbone**: EfficientNetV2-S preentrenado en ImageNet\n",
    "- **Transfer Learning**: Features congeladas (solo clasificador entrenable)\n",
    "- **Arquitectura simple**: Una sola capa Linear (in_features → num_classes)\n",
    "- **Sin regularización**: No BatchNorm, No Dropout, No capas ocultas\n",
    "\n",
    "**Características técnicas:**\n",
    "- Aprovecha features preentrenadas de EfficientNetV2-S\n",
    "- Mínimo número de parámetros entrenables\n",
    "- Enfoque directo y eficiente para clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f745bfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_v1(num_classes):\n",
    "    \"\"\"\n",
    "    Construye el modelo EfficientNetV2-S V1 con transfer learning\n",
    "    \n",
    "    Args:\n",
    "        num_classes (int): Numero de clases para el clasificador\n",
    "    \n",
    "    Returns:\n",
    "        model: Modelo EfficientNetV2-S modificado para V1\n",
    "    \"\"\"\n",
    "    # Cargar modelo preentrenado\n",
    "    model = models.efficientnet_v2_s(weights='IMAGENET1K_V1')\n",
    "    \n",
    "    # Congelar todas las capas del feature extractor\n",
    "    for param in model.features.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    # Obtener el numero de features de entrada del clasificador\n",
    "    in_features = model.classifier[1].in_features\n",
    "    \n",
    "    # Reemplazar el clasificador con una sola capa Linear (V1)\n",
    "    # Sin BatchNorm, sin Dropout, sin capas ocultas adicionales\n",
    "    model.classifier = nn.Linear(in_features, num_classes)\n",
    "    \n",
    "    print(f\"Modelo EfficientNetV2-S V1 creado exitosamente\")\n",
    "    print(f\"Features de entrada del clasificador: {in_features}\")\n",
    "    print(f\"Clases de salida: {num_classes}\")\n",
    "    print(f\"Arquitectura V1: Una sola capa Linear({in_features} -> {num_classes})\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b435a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir modelo V1\n",
    "print(\"Construyendo modelo EfficientNetV2-S V1...\")\n",
    "model = build_model_v1(num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "# Mostrar arquitectura del clasificador\n",
    "print(f\"\\nArquitectura del clasificador:\")\n",
    "print(model.classifier)\n",
    "\n",
    "# Verificar parametros entrenables\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "print(f\"\\nParametros totales: {total_params:,}\")\n",
    "print(f\"Parametros entrenables: {trainable_params:,}\")\n",
    "print(f\"Parametros congelados: {total_params - trainable_params:,}\")\n",
    "print(f\"Porcentaje entrenables: {(trainable_params/total_params)*100:.2f}%\")\n",
    "\n",
    "# Configurar criterion y optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "print(f\"\\nConfiguración del entrenamiento:\")\n",
    "print(f\"Loss function: CrossEntropyLoss\")\n",
    "print(f\"Optimizer: Adam (lr=0.001)\")\n",
    "print(f\"Early stopping: activado (patience=5)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca7895f",
   "metadata": {},
   "source": [
    "## 4. Entrenamiento con Early Stopping\n",
    "\n",
    "**Cumplimiento de requisitos 3.2:**\n",
    "- **Early stopping**: Patience=5 épocas para prevenir overfitting\n",
    "- **Registro de pérdidas**: Train y validation loss automático\n",
    "- **Optimizador**: Adam con learning rate 0.001\n",
    "- **Función de pérdida**: CrossEntropyLoss\n",
    "\n",
    "**Configuración de entrenamiento:**\n",
    "- Épocas máximas: 10 (con early stopping)\n",
    "- Monitoreo de validation loss para mejores pesos\n",
    "- Tracking automático de accuracy y pérdidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080d05e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el modelo\n",
    "num_epochs = 10\n",
    "patience = 5\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ENTRENAMIENTO DEL MODELO EFFICIENTNETV2-S V1\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "trained_model, train_losses, val_losses, train_accuracies, val_accuracies, best_epoch = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=num_epochs,\n",
    "    patience=patience,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ENTRENAMIENTO COMPLETADO\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa57a9b",
   "metadata": {},
   "source": [
    "## 5. Visualización de Curvas de Entrenamiento\n",
    "\n",
    "**Cumplimiento de requisitos 3.2:**\n",
    "- **Gráficos de curvas de pérdida**: Train vs Validation loss\n",
    "- **Curvas de accuracy**: Progreso durante entrenamiento\n",
    "- **Identificación de mejor época**: Marcada en las gráficas\n",
    "- **Análisis de convergencia**: Visual del comportamiento del modelo\n",
    "\n",
    "**Métricas visualizadas:**\n",
    "- Loss curves para detectar overfitting/underfitting\n",
    "- Accuracy curves para evaluar mejora del modelo\n",
    "- Best epoch marker para early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fac081f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar curvas de perdida\n",
    "print(\"Generando gráficas de métricas de entrenamiento...\")\n",
    "plot_training_metrics(train_losses, val_losses, train_accuracies, val_accuracies, best_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce2c04b",
   "metadata": {},
   "source": [
    "## 6. Evaluación Final en Conjunto de Prueba\n",
    "\n",
    "**Cumplimiento de requisitos 3.3:**\n",
    "- **Evaluación en conjunto de prueba**: Datos no vistos durante entrenamiento\n",
    "- **Matriz de confusión**: Visualización con heatmap por clases\n",
    "- **Métricas por clase**: Accuracy, Precision, Recall automáticos\n",
    "- **Classification report**: Detallado con F1-score y support\n",
    "\n",
    "**Objetivo:**\n",
    "- Medir rendimiento real del modelo V1 en datos independientes\n",
    "- Establecer baseline para comparación con Versión 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5109f05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluacion completa del modelo\n",
    "print(\"=\"*60)\n",
    "print(\"EVALUACION FINAL EN CONJUNTO DE TEST\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "test_accuracy, y_true, y_pred = evaluate_model(\n",
    "    model=trained_model,\n",
    "    test_loader=test_loader,\n",
    "    class_names=class_names,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e693a336",
   "metadata": {},
   "source": [
    "## 7. Guardado del Modelo Entrenado\n",
    "\n",
    "**Persistencia del modelo:**\n",
    "- Guardado de pesos del mejor modelo (best epoch)\n",
    "- Metadatos incluidos: accuracies, losses, class names\n",
    "- Estado del optimizador para posible continuación del entrenamiento\n",
    "\n",
    "**Información guardada:**\n",
    "- Model state dict con pesos entrenados\n",
    "- Historial completo de entrenamiento\n",
    "- Configuración de clases y métricas finales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4fe077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el modelo entrenado\n",
    "model_save_path = \"efficientnetv2_s_v1.pth\"\n",
    "\n",
    "torch.save({\n",
    "    'epoch': best_epoch,\n",
    "    'model_state_dict': trained_model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'train_losses': train_losses,\n",
    "    'val_losses': val_losses,\n",
    "    'test_accuracy': test_accuracy,\n",
    "    'class_names': class_names,\n",
    "    'num_classes': num_classes\n",
    "}, model_save_path)\n",
    "\n",
    "print(f\"Modelo guardado exitosamente en: {model_save_path}\")\n",
    "print(f\"Accuracy final en test: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PROYECTO COMPLETADO - EFFICIENTNETV2-S V1\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Mejor epoch: {best_epoch}\")\n",
    "print(f\"Mejor validation loss: {min(val_losses):.4f}\")\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Clases: {class_names}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765e0282",
   "metadata": {},
   "source": [
    "## 8. Sistema de Predicción Individual\n",
    "\n",
    "**Funcionalidades implementadas:**\n",
    "- Predicción de imágenes aleatorias del test set\n",
    "- Visualización de predicciones con confianza\n",
    "- Análisis detallado de resultados por imagen\n",
    "\n",
    "**Herramientas disponibles:**\n",
    "- Selección automática de muestras de prueba\n",
    "- Visualización de imagen + predicción + ground truth\n",
    "- Porcentajes de confianza por clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4e1d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPCION 1: Prediccion de imagenes aleatorias del conjunto de test\n",
    "print(\"\\nPredicciones en imagenes aleatorias del conjunto de test\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "test_dataset_path = f\"{data_dir}/test\"\n",
    "num_test_samples = 3  # Puedes cambiar este numero\n",
    "\n",
    "predict_random_from_test(\n",
    "    model=trained_model,\n",
    "    test_dataset_path=test_dataset_path,\n",
    "    class_names=class_names,\n",
    "    transform=val_test_transform,\n",
    "    device=device,\n",
    "    num_samples=num_test_samples\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23db862",
   "metadata": {},
   "source": [
    "## 9. Demostración Interactiva del Modelo\n",
    "\n",
    "**Funcionalidades de prueba:**\n",
    "- **Predicciones aleatorias**: Automáticas del conjunto de test\n",
    "- **Widget interactivo**: Selección manual de imágenes (si disponible)\n",
    "- **Análisis de confianza**: Distribución de probabilidades por clase\n",
    "\n",
    "**Propósito:**\n",
    "- Validar funcionamiento del modelo entrenado\n",
    "- Demostrar capacidades de clasificación\n",
    "- Análisis cualitativo de predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd30079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPCION 2: Widget interactivo para seleccionar imágenes\n",
    "print(\"\\nOPCION 2: Selector interactivo de imágenes\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "try:\n",
    "    from utils.select_widget_imagen import setup_widget_prediction, display_prediction_widget\n",
    "    \n",
    "    # Configurar el widget con las variables del modelo\n",
    "    setup_widget_prediction(\n",
    "        model=trained_model,\n",
    "        transform=val_test_transform,\n",
    "        classes=class_names,\n",
    "        device_type=device\n",
    "    )\n",
    "    \n",
    "    # Mostrar el widget\n",
    "    display_prediction_widget()\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"Error al importar el widget.\")\n",
    "    print(\"Verifica que ipywidgets esté instalado:\")\n",
    "    print(\"pip install ipywidgets\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"Usando método alternativo...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
